{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "luBJQsdMndGh"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "random.seed(42)  \n",
        "np.random.seed(42) \n",
        "torch.manual_seed(42)  \n",
        "torch.cuda.manual_seed_all(42)  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5QebXVI0QWN",
        "outputId": "810796aa-1428-4c6f-9825-80f8c8bc39bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "CnhAPBzl4X77",
        "outputId": "1e7bded6-9486-49f5-ea97-1586267c3e2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape: (284807, 31)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>...</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
              "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
              "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
              "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
              "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
              "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
              "\n",
              "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
              "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
              "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
              "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
              "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
              "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
              "\n",
              "        V26       V27       V28  Amount  Class  \n",
              "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
              "1  0.125895 -0.008983  0.014724    2.69      0  \n",
              "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
              "3 -0.221929  0.062723  0.061458  123.50      0  \n",
              "4  0.502292  0.219422  0.215153   69.99      0  \n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(\"/Users/tasosbliagkos/Documents/KD_project/creditcard.csv\")\n",
        "\n",
        "print(\"Shape:\", df.shape)\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "c-F8rQTV5hu0",
        "outputId": "51c23fa7-2987-4af1-a6b4-7afdac778e2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 284807 entries, 0 to 284806\n",
            "Data columns (total 31 columns):\n",
            " #   Column  Non-Null Count   Dtype  \n",
            "---  ------  --------------   -----  \n",
            " 0   Time    284807 non-null  float64\n",
            " 1   V1      284807 non-null  float64\n",
            " 2   V2      284807 non-null  float64\n",
            " 3   V3      284807 non-null  float64\n",
            " 4   V4      284807 non-null  float64\n",
            " 5   V5      284807 non-null  float64\n",
            " 6   V6      284807 non-null  float64\n",
            " 7   V7      284807 non-null  float64\n",
            " 8   V8      284807 non-null  float64\n",
            " 9   V9      284807 non-null  float64\n",
            " 10  V10     284807 non-null  float64\n",
            " 11  V11     284807 non-null  float64\n",
            " 12  V12     284807 non-null  float64\n",
            " 13  V13     284807 non-null  float64\n",
            " 14  V14     284807 non-null  float64\n",
            " 15  V15     284807 non-null  float64\n",
            " 16  V16     284807 non-null  float64\n",
            " 17  V17     284807 non-null  float64\n",
            " 18  V18     284807 non-null  float64\n",
            " 19  V19     284807 non-null  float64\n",
            " 20  V20     284807 non-null  float64\n",
            " 21  V21     284807 non-null  float64\n",
            " 22  V22     284807 non-null  float64\n",
            " 23  V23     284807 non-null  float64\n",
            " 24  V24     284807 non-null  float64\n",
            " 25  V25     284807 non-null  float64\n",
            " 26  V26     284807 non-null  float64\n",
            " 27  V27     284807 non-null  float64\n",
            " 28  V28     284807 non-null  float64\n",
            " 29  Amount  284807 non-null  float64\n",
            " 30  Class   284807 non-null  int64  \n",
            "dtypes: float64(30), int64(1)\n",
            "memory usage: 67.4 MB\n",
            "None\n",
            "\n",
            "Class value counts:\n",
            "Class\n",
            "0    284315\n",
            "1       492\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Class distribution (%):\n",
            "Class\n",
            "0    99.827251\n",
            "1     0.172749\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Describe numeric columns:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>284807.000000</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>...</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>284807.000000</td>\n",
              "      <td>284807.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>94813.859575</td>\n",
              "      <td>1.168375e-15</td>\n",
              "      <td>3.416908e-16</td>\n",
              "      <td>-1.379537e-15</td>\n",
              "      <td>2.074095e-15</td>\n",
              "      <td>9.604066e-16</td>\n",
              "      <td>1.487313e-15</td>\n",
              "      <td>-5.556467e-16</td>\n",
              "      <td>1.213481e-16</td>\n",
              "      <td>-2.406331e-15</td>\n",
              "      <td>...</td>\n",
              "      <td>1.654067e-16</td>\n",
              "      <td>-3.568593e-16</td>\n",
              "      <td>2.578648e-16</td>\n",
              "      <td>4.473266e-15</td>\n",
              "      <td>5.340915e-16</td>\n",
              "      <td>1.683437e-15</td>\n",
              "      <td>-3.660091e-16</td>\n",
              "      <td>-1.227390e-16</td>\n",
              "      <td>88.349619</td>\n",
              "      <td>0.001727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>47488.145955</td>\n",
              "      <td>1.958696e+00</td>\n",
              "      <td>1.651309e+00</td>\n",
              "      <td>1.516255e+00</td>\n",
              "      <td>1.415869e+00</td>\n",
              "      <td>1.380247e+00</td>\n",
              "      <td>1.332271e+00</td>\n",
              "      <td>1.237094e+00</td>\n",
              "      <td>1.194353e+00</td>\n",
              "      <td>1.098632e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>7.345240e-01</td>\n",
              "      <td>7.257016e-01</td>\n",
              "      <td>6.244603e-01</td>\n",
              "      <td>6.056471e-01</td>\n",
              "      <td>5.212781e-01</td>\n",
              "      <td>4.822270e-01</td>\n",
              "      <td>4.036325e-01</td>\n",
              "      <td>3.300833e-01</td>\n",
              "      <td>250.120109</td>\n",
              "      <td>0.041527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-5.640751e+01</td>\n",
              "      <td>-7.271573e+01</td>\n",
              "      <td>-4.832559e+01</td>\n",
              "      <td>-5.683171e+00</td>\n",
              "      <td>-1.137433e+02</td>\n",
              "      <td>-2.616051e+01</td>\n",
              "      <td>-4.355724e+01</td>\n",
              "      <td>-7.321672e+01</td>\n",
              "      <td>-1.343407e+01</td>\n",
              "      <td>...</td>\n",
              "      <td>-3.483038e+01</td>\n",
              "      <td>-1.093314e+01</td>\n",
              "      <td>-4.480774e+01</td>\n",
              "      <td>-2.836627e+00</td>\n",
              "      <td>-1.029540e+01</td>\n",
              "      <td>-2.604551e+00</td>\n",
              "      <td>-2.256568e+01</td>\n",
              "      <td>-1.543008e+01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>54201.500000</td>\n",
              "      <td>-9.203734e-01</td>\n",
              "      <td>-5.985499e-01</td>\n",
              "      <td>-8.903648e-01</td>\n",
              "      <td>-8.486401e-01</td>\n",
              "      <td>-6.915971e-01</td>\n",
              "      <td>-7.682956e-01</td>\n",
              "      <td>-5.540759e-01</td>\n",
              "      <td>-2.086297e-01</td>\n",
              "      <td>-6.430976e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.283949e-01</td>\n",
              "      <td>-5.423504e-01</td>\n",
              "      <td>-1.618463e-01</td>\n",
              "      <td>-3.545861e-01</td>\n",
              "      <td>-3.171451e-01</td>\n",
              "      <td>-3.269839e-01</td>\n",
              "      <td>-7.083953e-02</td>\n",
              "      <td>-5.295979e-02</td>\n",
              "      <td>5.600000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>84692.000000</td>\n",
              "      <td>1.810880e-02</td>\n",
              "      <td>6.548556e-02</td>\n",
              "      <td>1.798463e-01</td>\n",
              "      <td>-1.984653e-02</td>\n",
              "      <td>-5.433583e-02</td>\n",
              "      <td>-2.741871e-01</td>\n",
              "      <td>4.010308e-02</td>\n",
              "      <td>2.235804e-02</td>\n",
              "      <td>-5.142873e-02</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.945017e-02</td>\n",
              "      <td>6.781943e-03</td>\n",
              "      <td>-1.119293e-02</td>\n",
              "      <td>4.097606e-02</td>\n",
              "      <td>1.659350e-02</td>\n",
              "      <td>-5.213911e-02</td>\n",
              "      <td>1.342146e-03</td>\n",
              "      <td>1.124383e-02</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>139320.500000</td>\n",
              "      <td>1.315642e+00</td>\n",
              "      <td>8.037239e-01</td>\n",
              "      <td>1.027196e+00</td>\n",
              "      <td>7.433413e-01</td>\n",
              "      <td>6.119264e-01</td>\n",
              "      <td>3.985649e-01</td>\n",
              "      <td>5.704361e-01</td>\n",
              "      <td>3.273459e-01</td>\n",
              "      <td>5.971390e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>1.863772e-01</td>\n",
              "      <td>5.285536e-01</td>\n",
              "      <td>1.476421e-01</td>\n",
              "      <td>4.395266e-01</td>\n",
              "      <td>3.507156e-01</td>\n",
              "      <td>2.409522e-01</td>\n",
              "      <td>9.104512e-02</td>\n",
              "      <td>7.827995e-02</td>\n",
              "      <td>77.165000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>172792.000000</td>\n",
              "      <td>2.454930e+00</td>\n",
              "      <td>2.205773e+01</td>\n",
              "      <td>9.382558e+00</td>\n",
              "      <td>1.687534e+01</td>\n",
              "      <td>3.480167e+01</td>\n",
              "      <td>7.330163e+01</td>\n",
              "      <td>1.205895e+02</td>\n",
              "      <td>2.000721e+01</td>\n",
              "      <td>1.559499e+01</td>\n",
              "      <td>...</td>\n",
              "      <td>2.720284e+01</td>\n",
              "      <td>1.050309e+01</td>\n",
              "      <td>2.252841e+01</td>\n",
              "      <td>4.584549e+00</td>\n",
              "      <td>7.519589e+00</td>\n",
              "      <td>3.517346e+00</td>\n",
              "      <td>3.161220e+01</td>\n",
              "      <td>3.384781e+01</td>\n",
              "      <td>25691.160000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                Time            V1            V2            V3            V4  \\\n",
              "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
              "mean    94813.859575  1.168375e-15  3.416908e-16 -1.379537e-15  2.074095e-15   \n",
              "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
              "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
              "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
              "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
              "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
              "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
              "\n",
              "                 V5            V6            V7            V8            V9  \\\n",
              "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
              "mean   9.604066e-16  1.487313e-15 -5.556467e-16  1.213481e-16 -2.406331e-15   \n",
              "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
              "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
              "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
              "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
              "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
              "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
              "\n",
              "       ...           V21           V22           V23           V24  \\\n",
              "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
              "mean   ...  1.654067e-16 -3.568593e-16  2.578648e-16  4.473266e-15   \n",
              "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
              "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
              "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
              "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
              "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
              "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
              "\n",
              "                V25           V26           V27           V28         Amount  \\\n",
              "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
              "mean   5.340915e-16  1.683437e-15 -3.660091e-16 -1.227390e-16      88.349619   \n",
              "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
              "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
              "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
              "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
              "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
              "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
              "\n",
              "               Class  \n",
              "count  284807.000000  \n",
              "mean        0.001727  \n",
              "std         0.041527  \n",
              "min         0.000000  \n",
              "25%         0.000000  \n",
              "50%         0.000000  \n",
              "75%         0.000000  \n",
              "max         1.000000  \n",
              "\n",
              "[8 rows x 31 columns]"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(df.info())\n",
        "\n",
        "print(\"\\nClass value counts:\")\n",
        "print(df[\"Class\"].value_counts())\n",
        "print(\"\\nClass distribution (%):\")\n",
        "print(df[\"Class\"].value_counts(normalize=True) * 100)\n",
        "\n",
        "print(\"\\nDescribe numeric columns:\")\n",
        "df.describe()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7h2Ky_rimQCp"
      },
      "source": [
        "31 rows opou to prwto einai to time, o xronos se deuterolepta metaksu ths prwths sunallaghs sto dataset. meta exoume tis V1-V28 opou einai oi sthles pou proekupsan apo PCA kai einai ta features twn sunallagwn. kai telos exoume to class pou einai eite 1 eite 0. to 0 shmainei legit sunallagh enw to 1 fraud."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2acveg0iprM_",
        "outputId": "6b5cc87e-c3ad-4842-9fec-37ce7557e2f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NaN in Class: 0\n",
            "Unique values in Class: [0 1]\n"
          ]
        }
      ],
      "source": [
        "print(\"NaN in Class:\", df[\"Class\"].isna().sum())\n",
        "\n",
        "print(\"Unique values in Class:\", df[\"Class\"].unique())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2ZYaIZApw4k",
        "outputId": "5738fce6-8fbe-4631-cc6e-e47c58723bf4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "After cleaning:\n",
            "NaN in Class: 0\n",
            "Class\n",
            "0    284315\n",
            "1       492\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "df = df[df[\"Class\"].notna()]\n",
        "\n",
        "df[\"Class\"] = df[\"Class\"].astype(int)\n",
        "\n",
        "print(\"After cleaning:\")\n",
        "print(\"NaN in Class:\", df[\"Class\"].isna().sum())\n",
        "print(df[\"Class\"].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3soMHp4Qg16w",
        "outputId": "e3520759-ffba-4ba7-ff14-76c9c911c57d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(284807, 31)\n"
          ]
        }
      ],
      "source": [
        "print(df.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Εδώ κόβουμε το dataset σε τρία κομμάτια. Το train είναι αυτό με το οποίο θα εκπαιδεύσουμε τον teacher. Το validation το χρησιμοποιούμε για να παρακολουθούμε τι κάνει κατά τη διάρκεια του training. Το test το κρατάμε για το τέλος, για τελική αξιολόγηση. Το stratify=y κρατάει παρόμοιο fraud ratio σε όλα τα split. Δηλαδη: πόσες συναλλαγές είναι fraud / πόσες συνολικά; Στο dataset μας ειναι 0.17% Χωρις το stratification θα ειχαμε π.χ. 0.3% στο train, 0.1% στο validation, 0.5 sto test που ειναι απαγορευτικο και θα μας εβγαζε λαθος αφου το μοντέλο εκπαιδεύεται σε άλλη κατανομή, αξιολογείται σε άλλη, τα metrics δεν είναι συγκρίσιμα. Συγκεκριμενα βλεπουμε απο το output οτι τα δικα μας δεδομενα ειναι:\n",
        "\n",
        "Fraud ratio train: 0.0017254870488152324\n",
        "\n",
        "\n",
        "Fraud ratio val: 0.0017321691907960957\n",
        "\n",
        "\n",
        "Fraud ratio test: 0.0017321286456626562"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpJSEoakxHOE",
        "outputId": "6f2e5c62-772e-4d9a-e448-0434c3e1b967"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: (199364, 30)\n",
            "Val: (42721, 30)\n",
            "Test: (42722, 30)\n",
            "Fraud ratio train: 0.0017254870488152324\n",
            "Fraud ratio val: 0.0017321691907960957\n",
            "Fraud ratio test: 0.0017321286456626562\n"
          ]
        }
      ],
      "source": [
        "X = df.drop(columns=[\"Class\"]).values\n",
        "y = df[\"Class\"].values\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
        ")\n",
        "\n",
        "print(\"Train:\", X_train.shape)\n",
        "print(\"Val:\", X_val.shape)\n",
        "print(\"Test:\", X_test.shape)\n",
        "\n",
        "print(\"Fraud ratio train:\", y_train.mean())\n",
        "print(\"Fraud ratio val:\", y_val.mean())\n",
        "print(\"Fraud ratio test:\", y_test.mean())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Εδώ κανονικοποιούμε όλα τα features ώστε να έχουν παρόμοια κλίμακα. Αυτό βοηθάει πολύ τα νευρωνικά να εκπαιδευτούν σταθερά, ειδικά επειδή το Amount και το Time μπορεί να είναι σε άλλη κλίμακα από τα PCA components.\n",
        "\n",
        "\n",
        "Χωρίς scaling:\n",
        "\n",
        "το Amount και το Time θα “σκεπάζουν” τα PCA features\n",
        "\n",
        "το μοντέλο θα βασίζεται υπερβολικά σε αυτά\n",
        "\n",
        "το KD αργότερα θα αποστάζει λάθος patterns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "iv4CWOrzx6r7"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val   = scaler.transform(X_val)\n",
        "X_test  = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xqwxx_lhaqAB"
      },
      "source": [
        "edw sthn ousia allazw ta numpy arrays se batches kai tensors wste na xrhsimopoihthoun sto neurwniko mou diktuo. ftiaxnoume nea datasets ta opoia mesa periexoun ta features kai ta labels. Ta dataloaders ta opoia xrhsimopoioume gia na paroume ta dedomena se batches twn 512 kai 1024 gia ta val kai test modes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vclO6NCxx_CS",
        "outputId": "a6911a71-6835-4704-a3ab-fd05210f9764"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(199364, 42721, 42722)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class FraudDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.float32)\n",
        "        self.y = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "\n",
        "train_ds = FraudDataset(X_train, y_train)\n",
        "val_ds   = FraudDataset(X_val, y_val)\n",
        "test_ds  = FraudDataset(X_test, y_test)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=512, shuffle=False)\n",
        "val_loader   = DataLoader(val_ds, batch_size=1024, shuffle=False)\n",
        "test_loader  = DataLoader(test_ds, batch_size=1024, shuffle=False)\n",
        "\n",
        "len(train_ds), len(val_ds), len(test_ds)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jY6wy_CveEkS"
      },
      "source": [
        "Edw exoume ftiaksei to basiko neurwna tou teacher model mas opou to input (30) tha pernaei apo 256 neurwnes sthn arxh, 128 meta kai 64 sto telos kai kathe fora tha efarmozetai RELU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2X57vvZyBl0",
        "outputId": "eb4a2081-073e-45ec-c515-910d972ab6e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n",
            "Input dim: 30\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "MLP(\n",
              "  (net): Sequential(\n",
              "    (0): Linear(in_features=30, out_features=128, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
              "    (4): ReLU()\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=64, out_features=32, bias=True)\n",
              "    (7): ReLU()\n",
              "    (8): Dropout(p=0.5, inplace=False)\n",
              "    (9): Linear(in_features=32, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "input_dim = X_train.shape[1] #30 inputs, sthn ousia kathe sunallagh monh ths.\n",
        "print(\"Input dim:\", input_dim)\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dims, dropout_rate=0.5):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        prev = input_dim\n",
        "        for h in hidden_dims:\n",
        "            layers.append(nn.Linear(prev, h))\n",
        "            layers.append(nn.ReLU())\n",
        "            layers.append(nn.Dropout(dropout_rate))  # evala dropout gia na mhn kanei overfit to modelo, apenergopoiei tuxaia neurwnes prokeimenou na mhn katalhksoun kapoioi neurwnes ta basizontai polu se allous.\n",
        "            prev = h\n",
        "        layers.append(nn.Linear(prev, 2))\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "#phga apo 256-128-64 se 128-64-32\n",
        "teacher = MLP(input_dim, hidden_dims=[128, 64, 32], dropout_rate=0.5).to(device)\n",
        "\n",
        "teacher\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOwbA3iAlYcS"
      },
      "source": [
        "εδω εχουμε τον κωδικα του teacher που περιεχει class weights οπου το μοντελο στην ουσια η κλαση με τα λιγοτερα δειγματα fraud ειναι αυτη που τιμωρει περισσοτερο το μοντελο σε περιπτωση λαθους \n",
        "\n",
        "εχουμε υλοποιησει εναν adam optimizer o opoios einai algorithmos pou prosarmozei to vhma mathishs kai bohtha sth sugklisi twn dedomenwn. \n",
        "\n",
        "kai L2 regularization pou vohthaei sto overfitting \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1E-qiVyLhgh-",
        "outputId": "aeab4320-bb4e-4bbe-986b-7d5bcd9cc3b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class weights: tensor([  0.5009, 289.7733])\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "classes = np.array([0, 1])\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight=\"balanced\",\n",
        "    classes=classes,\n",
        "    y=y_train\n",
        ")\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
        "print(\"Class weights:\", class_weights)\n",
        "\n",
        "\n",
        "def train_teacher(model, train_loader, val_loader, epochs=5, lr=1e-4, patience=3):\n",
        "   \n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)  # Προσθήκη weight decay για L2 regularization\n",
        "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "    best_val_loss = float('inf')\n",
        "    epochs_without_improvement = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(xb)\n",
        "            loss = criterion(logits, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item() * xb.size(0)\n",
        "\n",
        "        avg_train_loss = total_loss / len(train_loader.dataset)\n",
        "\n",
        "        model.eval()\n",
        "        total_val_loss = 0.0\n",
        "        correct, total = 0, 0\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in val_loader:\n",
        "                xb, yb = xb.to(device), yb.to(device)\n",
        "                logits = model(xb)\n",
        "                loss = criterion(logits, yb)\n",
        "                total_val_loss += loss.item() * xb.size(0)\n",
        "\n",
        "                preds = logits.argmax(dim=1)\n",
        "                correct += (preds == yb).sum().item()\n",
        "                total += yb.size(0)\n",
        "\n",
        "        avg_val_loss = total_val_loss / len(val_loader.dataset)\n",
        "        val_acc = correct / total if total > 0 else 0.0\n",
        "\n",
        "        print(f\"Epoch {epoch+1}: train_loss={avg_train_loss:.4f}, val_loss={avg_val_loss:.4f}, val_acc={val_acc:.4f}\")\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            epochs_without_improvement = 0  \n",
        "        else:\n",
        "            epochs_without_improvement += 1\n",
        "            if epochs_without_improvement >= patience:\n",
        "                print(\"Early stopping triggered!\")\n",
        "                break \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWM6ThshUjv3"
      },
      "source": [
        "parathroume ooti to baros sto class 0 (non fraud) einai 0.5009 enw sto class 1 (fraud) einai 289.7733 to opoio einai thetiko shmadi kathws to modelo mas dinei megaluterh varutita stis fraud sunallages ap oti stis legit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsNoso5rlcfx"
      },
      "source": [
        "Εδώ κάνουμε δύο πράγματα. Πρώτον, υπολογίζουμε class_weights για να δώσουμε πολύ μεγαλύτερο βάρος στα fraud samples, επειδή είναι πολύ λίγα. Αυτό μπαίνει μέσα στο CrossEntropyLoss ώστε το loss να “πονάει” περισσότερο όταν κάνουμε λάθος στην fraud κλάση. Δεύτερον, γράφουμε τον training loop του teacher: για κάθε epoch, περνάει όλα τα batches, κάνει forward → loss → backward → optimizer step και στο τέλος υπολογίζει validation accuracy για να δούμε αν βελτιώνεται.\n",
        "Adam optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OryILguHhjXp",
        "outputId": "61732111-68de-48b3-e1c0-70a961d4b8d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: train_loss=0.5977, val_loss=0.4849, val_acc=0.9990\n",
            "Epoch 2: train_loss=0.4524, val_loss=0.3382, val_acc=0.9989\n",
            "Epoch 3: train_loss=0.3028, val_loss=0.2602, val_acc=0.9975\n",
            "Epoch 4: train_loss=0.2445, val_loss=0.2360, val_acc=0.9945\n",
            "Epoch 5: train_loss=0.2095, val_loss=0.2292, val_acc=0.9906\n",
            "Epoch 6: train_loss=0.1775, val_loss=0.2323, val_acc=0.9902\n",
            "Epoch 7: train_loss=0.1961, val_loss=0.2282, val_acc=0.9891\n",
            "Epoch 8: train_loss=0.1593, val_loss=0.2328, val_acc=0.9898\n",
            "Epoch 9: train_loss=0.1581, val_loss=0.2324, val_acc=0.9899\n",
            "Epoch 10: train_loss=0.1711, val_loss=0.2260, val_acc=0.9893\n",
            "Epoch 11: train_loss=0.1506, val_loss=0.2269, val_acc=0.9894\n",
            "Epoch 12: train_loss=0.1545, val_loss=0.2254, val_acc=0.9890\n",
            "Epoch 13: train_loss=0.1332, val_loss=0.2237, val_acc=0.9881\n",
            "Epoch 14: train_loss=0.1293, val_loss=0.2246, val_acc=0.9881\n",
            "Epoch 15: train_loss=0.1361, val_loss=0.2242, val_acc=0.9889\n"
          ]
        }
      ],
      "source": [
        "train_teacher(teacher, train_loader, val_loader, epochs=15, lr=1e-4)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Μετράει πόσο λάθος έκανε ο Δάσκαλος πάνω στα δεδομένα που χρησιμοποιεί για να εκπαιδευτεί.\n",
        "\n",
        "Μετράει το λάθος του μοντέλου σε δεδομένα που δεν έχει ξαναδεί ποτέ (Validation Set). Είναι σαν ένα \"τεστ προσομοίωσης\".\n",
        "\n",
        "Το ποσοστό των σωστών προβλέψεων (Legit ως Legit και Fraud ως Fraud) πάνω στο Validation Set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8tgBV53VcFR"
      },
      "source": [
        "Η σταθερή μείωση δείχνει ότι το μοντέλο εκπαιδεύεται ομαλά και ότι δεν αντιμετωπίζει προβλήματα όπως vanishing gradients ή overfitting.\n",
        "\n",
        "Η validation accuracy δείχνει πόσο καλά το μοντέλο γενικεύει στα δεδομένα που δεν έχει ξαναδεί.\n",
        "\n",
        "Αναγκαστικά άλλαξα τα layers απο 256-128-64 σε 128-64-32 για να μην εχουμε overfitting στο μοντελο πραγμα που φαινεται απο το val_loss το οποιο παραμενει κατα βαση σταθερο."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TWDuA2Dhqk6",
        "outputId": "59ab6091-bda2-4d92-afbc-1bc0e90f117b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Teacher performance on test set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9997    0.9996    0.9996     42648\n",
            "           1     0.7692    0.8108    0.7895        74\n",
            "\n",
            "    accuracy                         0.9993     42722\n",
            "   macro avg     0.8845    0.9052    0.8945     42722\n",
            "weighted avg     0.9993    0.9993    0.9993     42722\n",
            "\n",
            "ROC AUC: 0.9752020943284307\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    all_y = []\n",
        "    all_p = []\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in loader:\n",
        "            xb = xb.to(device)\n",
        "            logits = model(xb)\n",
        "            probs = F.softmax(logits, dim=1)[:, 1].cpu().numpy()  # Αποθήκευση των probabilities για την κλάση fraud\n",
        "            all_p.extend(probs)\n",
        "            all_y.extend(yb.numpy())\n",
        "\n",
        "    preds = [1 if p > 0.95 else 0 for p in all_p]\n",
        "    print(classification_report(all_y, preds, digits=4))\n",
        "    try:\n",
        "        print(\"ROC AUC:\", roc_auc_score(all_y, all_p))\n",
        "    except ValueError:\n",
        "        print(\"ROC AUC: cannot compute\")\n",
        "\n",
        "print(\"Teacher performance on test set:\")\n",
        "evaluate(teacher, test_loader)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NA UPOLOGISW POSO PERISSORERO XRONO KATANALWNEI OTAN TO THRESHOLD EINAI STO 0.95"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Από όλες τις συναλλαγές που το μοντέλο βάφτισε ως απάτη, πόσες ήταν πραγματικά απάτες;\n",
        "\n",
        "Από όλες τις πραγματικές απάτες που υπήρχαν στο dataset, πόσες κατάφερε το μοντέλο να βρει\n",
        "\n",
        "Ποια είναι η συνολική ισορροπία μεταξύ Precision και Recall\n",
        "\n",
        "Τον πραγματικό αριθμό των δειγμάτων (συναλλαγών) που ανήκουν σε κάθε κλάση στο συγκεκριμένο test set.\n",
        "\n",
        "\n",
        "Το ROC AUC λέει πόσο καλή είναι η ποιότητα του διαχωρισμού που κάνει το μοντέλο σου συνολικά. Αν επιλέξω τυχαία μία πραγματική απάτη και μία νόμιμη συναλλαγή από το dataset, υπάρχει 97.21% πιθανότητα ο Teacher να δώσει υψηλότερο \"σκορ απάτης\" στην πραγματική απάτη."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIxsYmvas8Ms"
      },
      "source": [
        "ΠΡΟΧΩΡΑΩ ΣΤΟ STUDENT MODEL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Εδω εχουμε το student model που αποτελειται απο ενα νευρωνικο δικτυο με 30 εισοδους (προφανως) και εχει 2 κρυφα επιπεδα των 32 νευρωνων το πρωτο το οποιο συρικνωνεται σε 16 αργοτερα. Student είναι δηλαδή σημαντικά μικρότερος (λιγότερα layers και πολύ λιγότεροι νευρώνες ανά επίπεδο).\n",
        "\n",
        "Θετω το dropout rate του student model στο 0.2 αντιθετα με το teacher model που ειναι στο 0.5. Αυτο συμβαίνει επειδη στο teacher ειναι πολυ μεγαλυτερο το μοντελο και εχει πολλους περισσοτερους νευρωνες με αποτελεσμα πολλοι απο αυτους πολλες φορες να σταματανε να μαθαινουν και να επηρεαζονται απο αλλους συγκεκριμενους νευρωνες και να προκαλουν overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Student Architecture:\n",
            "MLP(\n",
            "  (net): Sequential(\n",
            "    (0): Linear(in_features=30, out_features=32, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "    (3): Linear(in_features=32, out_features=16, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Dropout(p=0.2, inplace=False)\n",
            "    (6): Linear(in_features=16, out_features=2, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "student = MLP(input_dim, hidden_dims=[32, 16], dropout_rate=0.2).to(device)\n",
        "\n",
        "print(\"Student Architecture:\")\n",
        "print(student)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Στη συνεχεια εχουμε την καρδια του KD οπου για αρχη μετραμε το loss που συγκρινει τις προβλεψεις του μαθητη με τις πραγματικες τιμες που ειναι αποθηκευμενες στα labels. Χρησιμοποιω τα class weights για να δινεται περισσοτερη βαση στις απατες πολυ περισσοτερο απ τις κανονικες συναλλαγες.\n",
        "\n",
        "Στη συνεχεια εχω το soft loss. Το κανω αυτο επειδη θελω ο μαθητης να μαθαινει πραγματικα. ΔΗΛΑΔΗ, οσο εχω το Τ=5 αν ο καθηγητης εμπεριεχει τιμες που ειναι ακραιες οπως 0.99 για legit και 0.01 για fraud το μοντελο του μαθητη δεν θα μπορουσε να μαθει, ενω με το Τ=5 οι ακραιες αυτες τιμες γινονται πιο ομαλες, πχ στο 0.73 και στο 0.27.\n",
        "\n",
        "Το KL Divergence ειναι ενα metric που χρησιμοποιω για να μετρησω ποσο πολυ διαφερουν οι αποψεις του μαθητη σε σχεση με τις αποψεις του καθηγητη, θελω ο μαθητης να πλησιαζει τις πιθανοτητες του καθηγητη\n",
        "\n",
        "Με λιγα λογια σε αυτη τη συναρτηση βαζουμε τα θεμελια προκειμενου το μοντελο μαθητη να μη μαθαινει απλα ειναι απατη-ειναι legit και τελος. Μπαινει στη διαδικασια να δει για ποιο λογο εχει παρθει η αποφαση."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "def loss_kd(outputs, labels, teacher_outputs, T=5.0, alpha=0.7):\n",
        "    hard_loss = F.cross_entropy(outputs, labels, weight=class_weights)\n",
        "    soft_targets = F.log_softmax(outputs / T, dim=1)\n",
        "    soft_labels = F.softmax(teacher_outputs / T, dim=1)\n",
        "\n",
        "    distillation_loss = F.kl_div(soft_targets, soft_labels, reduction='batchmean') * (T ** 2)\n",
        "    return alpha * distillation_loss + (1. - alpha) * hard_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Πριν ξεκινήσει οτιδήποτε, θέτουμε τον Δάσκαλο σε eval() mode. Αυτό απενεργοποιεί το Dropout. Λέμε στην PyTorch να μην υπολογίζει κλίσεις για τον Δάσκαλο, εξοικονομώντας μνήμη, αφού ο Δάσκαλος δεν θα αλλάξει πια"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15, Loss: 0.4779\n",
            "Epoch 2/15, Loss: 0.1165\n",
            "Epoch 3/15, Loss: 0.1035\n",
            "Epoch 4/15, Loss: 0.0944\n",
            "Epoch 5/15, Loss: 0.0891\n",
            "Epoch 6/15, Loss: 0.0824\n",
            "Epoch 7/15, Loss: 0.0775\n",
            "Epoch 8/15, Loss: 0.0737\n",
            "Epoch 9/15, Loss: 0.0694\n",
            "Epoch 10/15, Loss: 0.0660\n",
            "Epoch 11/15, Loss: 0.0631\n",
            "Epoch 12/15, Loss: 0.0621\n",
            "Epoch 13/15, Loss: 0.0592\n",
            "Epoch 14/15, Loss: 0.0583\n",
            "Epoch 15/15, Loss: 0.0535\n"
          ]
        }
      ],
      "source": [
        "def train_student(student_model, teacher_model, train_loader, val_loader, epochs=10, lr=1e-3):\n",
        "    optimizer = torch.optim.Adam(student_model.parameters(), lr=lr)\n",
        "    teacher_model.eval()\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        student_model.train()\n",
        "        train_loss = 0.0\n",
        "        \n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            with torch.no_grad():\n",
        "                teacher_logits = teacher_model(xb)\n",
        "            \n",
        "            student_logits = student_model(xb) #edw o mathitis koitazei ta 30 features kai prospathei na mantepsei an prokeitai gia apath. Sthn arxh oi apanthseis tou einai random.\n",
        "            \n",
        "            #edw ginetai to distillation. Lambanei shma apo ta dedomena (kata 30%) oti ekanes lathos px kai apo ton daskalo kata 70% prokeimenou na elegksei tis pithanothtes pou tou dinontai.\n",
        "            loss = loss_kd(student_logits, yb, teacher_logits, T=5.0, alpha=0.7)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            train_loss += loss.item() * xb.size(0)\n",
        "            \n",
        "        avg_loss = train_loss / len(train_loader.dataset)\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}\")\n",
        "train_student(student, teacher, train_loader, val_loader, epochs=15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Student performance on test set (Threshold 0.95):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9996    0.9995    0.9996     42648\n",
            "           1     0.7468    0.7973    0.7712        74\n",
            "\n",
            "    accuracy                         0.9992     42722\n",
            "   macro avg     0.8732    0.8984    0.8854     42722\n",
            "weighted avg     0.9992    0.9992    0.9992     42722\n",
            "\n",
            "ROC AUC: 0.9756623358023189\n"
          ]
        }
      ],
      "source": [
        "print(\"Student performance on test set (Threshold 0.95):\")\n",
        "evaluate(student, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Teacher Inference Time: 0.0123s\n",
            "Student Inference Time: 0.0033s\n",
            "Speedup: 3.72x\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import torch\n",
        "\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
        "\n",
        "teacher.eval()\n",
        "student.eval()\n",
        "\n",
        "start_teacher = time.time()\n",
        "with torch.no_grad():\n",
        "    _ = teacher(X_test_tensor)\n",
        "end_teacher = time.time()\n",
        "teacher_latency = end_teacher - start_teacher\n",
        "\n",
        "start_student = time.time()\n",
        "with torch.no_grad():\n",
        "    _ = student(X_test_tensor)\n",
        "end_student = time.time()\n",
        "student_latency = end_student - start_student\n",
        "\n",
        "print(f\"Teacher Inference Time: {teacher_latency:.4f}s\")\n",
        "print(f\"Student Inference Time: {student_latency:.4f}s\")\n",
        "print(f\"Speedup: {teacher_latency / student_latency:.2f}x\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Teacher - Μέσος Χρόνος: 0.0093s (+/- 0.0008s)\n",
            "Student - Μέσος Χρόνος: 0.0027s (+/- 0.0002s)\n",
            "\n",
            " Average speedup: 3.45\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def stable_benchmark(model, input_data, name, iterations=50):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for _ in range(10):\n",
        "            _ = model(input_data)\n",
        "    \n",
        "    times = []\n",
        "    with torch.no_grad():\n",
        "        for _ in range(iterations):\n",
        "            start = time.time()\n",
        "            _ = model(input_data)\n",
        "            times.append(time.time() - start)\n",
        "    \n",
        "    avg_time = np.mean(times)\n",
        "    std_time = np.std(times)\n",
        "    \n",
        "    print(f\"{name} - Μέσος Χρόνος: {avg_time:.4f}s (+/- {std_time:.4f}s)\")\n",
        "    return avg_time\n",
        "\n",
        "avg_teacher = stable_benchmark(teacher, X_test_tensor, \"Teacher\")\n",
        "avg_student = stable_benchmark(student, X_test_tensor, \"Student\")\n",
        "\n",
        "print(f\"\\n Average speedup: {avg_teacher / avg_student:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training XGBoost...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/tasosbliagkos/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:158: UserWarning: [18:15:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Random Forest...\n",
            "\n",
            "Final Comparison Table (Threshold 0.95 except for Random forest which uses 0.5):\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>ROC AUC</th>\n",
              "      <th>F1-Score</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Latency (s)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.972354</td>\n",
              "      <td>0.867647</td>\n",
              "      <td>0.797297</td>\n",
              "      <td>0.951613</td>\n",
              "      <td>0.023554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>0.930895</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.702703</td>\n",
              "      <td>0.962963</td>\n",
              "      <td>0.044272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Teacher (Master)</td>\n",
              "      <td>0.975202</td>\n",
              "      <td>0.789474</td>\n",
              "      <td>0.810811</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.026468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Student (Distilled)</td>\n",
              "      <td>0.975662</td>\n",
              "      <td>0.771242</td>\n",
              "      <td>0.797297</td>\n",
              "      <td>0.746835</td>\n",
              "      <td>0.003773</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Model   ROC AUC  F1-Score    Recall  Precision  Latency (s)\n",
              "2              XGBoost  0.972354  0.867647  0.797297   0.951613     0.023554\n",
              "3        Random Forest  0.930895  0.812500  0.702703   0.962963     0.044272\n",
              "0     Teacher (Master)  0.975202  0.789474  0.810811   0.769231     0.026468\n",
              "1  Student (Distilled)  0.975662  0.771242  0.797297   0.746835     0.003773"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Student is 6.24x faster than XGBoost\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
        "\n",
        "scale_weight = (len(y_train) - sum(y_train)) / sum(y_train)\n",
        "\n",
        "print(\"Training XGBoost...\")\n",
        "xgb_model = XGBClassifier(\n",
        "    scale_pos_weight=scale_weight, \n",
        "    random_state=42, \n",
        "    use_label_encoder=False, \n",
        "    eval_metric='logloss'\n",
        ")\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Training Random Forest...\")\n",
        "rf_model = RandomForestClassifier(\n",
        "    class_weight='balanced', \n",
        "    random_state=42, \n",
        "    n_jobs=-1\n",
        ")\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "def full_benchmark(model, X_test, y_test, name, is_torch=False, threshold=0.95):\n",
        "   \n",
        "    start = time.time()\n",
        "    \n",
        "    if is_torch:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            \n",
        "            inputs = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
        "            logits = model(inputs)\n",
        "            \n",
        "            probs = torch.softmax(logits, dim=1)[:, 1].cpu().numpy()\n",
        "    else:\n",
        "       \n",
        "        probs = model.predict_proba(X_test)[:, 1]\n",
        "    \n",
        "    end = time.time()\n",
        "    latency = end - start\n",
        "    \n",
        "\n",
        "    preds = [1 if p > threshold else 0 for p in probs]\n",
        "    \n",
        "\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, preds, average='binary')\n",
        "    \n",
        "\n",
        "    auc = roc_auc_score(y_test, probs)\n",
        "    \n",
        "    return {\n",
        "        \"Model\": name,\n",
        "        \"ROC AUC\": auc,\n",
        "        \"F1-Score\": f1,\n",
        "        \"Recall\": recall,\n",
        "        \"Precision\": precision,\n",
        "        \"Latency (s)\": latency\n",
        "    }\n",
        "results = []\n",
        "\n",
        "results.append(full_benchmark(teacher, X_test, y_test, \"Teacher (Master)\", is_torch=True))\n",
        "results.append(full_benchmark(student, X_test, y_test, \"Student (Distilled)\", is_torch=True))\n",
        "\n",
        "results.append(full_benchmark(xgb_model, X_test, y_test, \"XGBoost\", is_torch=False))\n",
        "results.append(full_benchmark(rf_model, X_test, y_test, \"Random Forest\", is_torch=False, threshold=0.5))\n",
        "\n",
        "df_final = pd.DataFrame(results)\n",
        "\n",
        "print(\"\\nFinal Comparison Table (Threshold 0.95 except for Random forest which uses 0.5):\")\n",
        "display(df_final.sort_values(by=\"F1-Score\", ascending=False))\n",
        "\n",
        "xgb_latency = df_final.loc[df_final['Model'] == 'XGBoost', 'Latency (s)'].values[0]\n",
        "student_latency = df_final.loc[df_final['Model'] == 'Student (Distilled)', 'Latency (s)'].values[0]\n",
        "print(f\"\\nStudent is {xgb_latency / student_latency:.2f}x faster than XGBoost\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New PaySim Input Dimension: 10 features\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "#neo paysim dataset \n",
        "df = pd.read_csv('paysim dataset.csv')\n",
        "df = pd.get_dummies(df, columns=['type'], drop_first=True)\n",
        "\n",
        "X = df.drop(['isFraud', 'isFlaggedFraud', 'nameOrig', 'nameDest'], axis=1)\n",
        "y = df['isFraud']\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y, test_size=0.3, stratify=y, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
        "input_dim = X_train.shape[1]\n",
        "class TeacherNetwork(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(TeacherNetwork, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 2)\n",
        "        )\n",
        "    def forward(self, x): return self.net(x)\n",
        "\n",
        "class StudentNetwork(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(StudentNetwork, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(32, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, 2)\n",
        "        )\n",
        "    def forward(self, x): return self.net(x)\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "teacher = TeacherNetwork(input_dim).to(device)\n",
        "student = StudentNetwork(input_dim).to(device)\n",
        "\n",
        "print(f\"New PaySim Input Dimension: {input_dim} features\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Teacher Epoch 1, Avg Loss: 0.0375\n",
            "Teacher Epoch 2, Avg Loss: 0.0333\n",
            "Teacher Epoch 3, Avg Loss: 0.0319\n",
            "Teacher Epoch 4, Avg Loss: 0.0321\n",
            "Teacher Epoch 5, Avg Loss: 0.0323\n",
            "Teacher Epoch 6, Avg Loss: 0.0309\n",
            "Teacher Epoch 7, Avg Loss: 0.0308\n",
            "Teacher Epoch 8, Avg Loss: 0.0298\n",
            "Teacher Epoch 9, Avg Loss: 0.0292\n",
            "Teacher Epoch 10, Avg Loss: 0.0289\n",
            "Student KD Epoch 1, Avg Loss: 0.0199\n",
            "Student KD Epoch 2, Avg Loss: 0.0165\n",
            "Student KD Epoch 3, Avg Loss: 0.0157\n",
            "Student KD Epoch 4, Avg Loss: 0.0152\n",
            "Student KD Epoch 5, Avg Loss: 0.0151\n",
            "Student KD Epoch 6, Avg Loss: 0.0146\n",
            "Student KD Epoch 7, Avg Loss: 0.0146\n",
            "Student KD Epoch 8, Avg Loss: 0.0150\n",
            "Student KD Epoch 9, Avg Loss: 0.0145\n",
            "Student KD Epoch 10, Avg Loss: 0.0143\n"
          ]
        }
      ],
      "source": [
        "T = 2.0  \n",
        "alpha = 0.5  \n",
        "learning_rate = 1e-3\n",
        "fraud_ratio = y_train.mean()\n",
        "weights = torch.tensor([1.0, np.sqrt(1.0 / fraud_ratio)], dtype=torch.float32).to(device)\n",
        "criterion_hard = nn.CrossEntropyLoss(weight=weights)\n",
        "\n",
        "optimizer_teacher = optim.Adam(teacher.parameters(), lr=learning_rate)\n",
        "optimizer_student = optim.Adam(student.parameters(), lr=learning_rate)\n",
        "train_teacher(epochs=10)\n",
        "train_student_kd(epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Threshold for Teacher: 0.9315\n",
            "Best Threshold for Student: 0.7835\n",
            "Best Threshold for XGBoost: 0.8403\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def find_best_threshold(model, X_test, y_test, is_torch=True):\n",
        "   \n",
        "    if is_torch:\n",
        "        model.eval() \n",
        "        with torch.no_grad():\n",
        "            inputs = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
        "            logits = model(inputs)\n",
        "            probs = torch.softmax(logits, dim=1)[:, 1].cpu().numpy()\n",
        "    else:\n",
        "        probs = model.predict_proba(X_test)[:, 1]\n",
        "    \n",
        " \n",
        "    precisions, recalls, thresholds = precision_recall_curve(y_test, probs)\n",
        "    \n",
        "  \n",
        "    f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-10)\n",
        "    best_idx = np.argmax(f1_scores)\n",
        "    \n",
        "\n",
        "    return thresholds[best_idx], f1_scores[best_idx]\n",
        "\n",
        "\n",
        "best_t_teacher, _ = find_best_threshold(teacher, X_test, y_test, is_torch=True)\n",
        "best_t_student, _ = find_best_threshold(student, X_test, y_test, is_torch=True)\n",
        "best_t_xgb, _ = find_best_threshold(xgb_model, X_test, y_test, is_torch=False)\n",
        "\n",
        "print(f\"Best Threshold for Teacher: {best_t_teacher:.4f}\")\n",
        "print(f\"Best Threshold for Student: {best_t_student:.4f}\")\n",
        "print(f\"Best Threshold for XGBoost: {best_t_xgb:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retraining XGBoost with Tuned Scale Weight: 27.82\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/tasosbliagkos/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:158: UserWarning: [15:34:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-3 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-3 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-3 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-3 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-3 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-3 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-3 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-3 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-3 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-3 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
              "              feature_types=None, gamma=None, grow_policy=None,\n",
              "              importance_type=None, interaction_constraints=None,\n",
              "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
              "              max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
              "              max_leaves=None, min_child_weight=None, missing=nan,\n",
              "              monotone_constraints=None, multi_strategy=None, n_estimators=100,\n",
              "              n_jobs=None, num_parallel_tree=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
              "              feature_types=None, gamma=None, grow_policy=None,\n",
              "              importance_type=None, interaction_constraints=None,\n",
              "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
              "              max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
              "              max_leaves=None, min_child_weight=None, missing=nan,\n",
              "              monotone_constraints=None, multi_strategy=None, n_estimators=100,\n",
              "              n_jobs=None, num_parallel_tree=None, random_state=42, ...)</pre></div> </div></div></div></div>"
            ],
            "text/plain": [
              "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric='logloss',\n",
              "              feature_types=None, gamma=None, grow_policy=None,\n",
              "              importance_type=None, interaction_constraints=None,\n",
              "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
              "              max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
              "              max_leaves=None, min_child_weight=None, missing=nan,\n",
              "              monotone_constraints=None, multi_strategy=None, n_estimators=100,\n",
              "              n_jobs=None, num_parallel_tree=None, random_state=42, ...)"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "scale_weight_tuned = np.sqrt((len(y_train) - sum(y_train)) / sum(y_train))\n",
        "\n",
        "print(f\"Retraining XGBoost with Tuned Scale Weight: {scale_weight_tuned:.2f}\")\n",
        "\n",
        "xgb_model = XGBClassifier(\n",
        "    scale_pos_weight=scale_weight_tuned, \n",
        "    random_state=42, \n",
        "    use_label_encoder=False, \n",
        "    eval_metric='logloss',\n",
        "    n_estimators=100, \n",
        "    max_depth=6\n",
        ")\n",
        "\n",
        "xgb_model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Threshold for XGBoost on PaySim: 0.8403\n"
          ]
        }
      ],
      "source": [
        "best_t_xgb, _ = find_best_threshold(xgb_model, X_test, y_test, is_torch=False)\n",
        "\n",
        "print(f\"Best Threshold for XGBoost on PaySim: {best_t_xgb:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Final comparison: PaySim Dataset (10 Features)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>ROC AUC</th>\n",
              "      <th>F1-Score</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Latency (s)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>XGBoost (Tuned)</td>\n",
              "      <td>0.999745</td>\n",
              "      <td>0.908788</td>\n",
              "      <td>0.885552</td>\n",
              "      <td>0.933276</td>\n",
              "      <td>0.384750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>0.993781</td>\n",
              "      <td>0.859232</td>\n",
              "      <td>0.762987</td>\n",
              "      <td>0.983264</td>\n",
              "      <td>0.559111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Student (Distilled)</td>\n",
              "      <td>0.997468</td>\n",
              "      <td>0.794805</td>\n",
              "      <td>0.745130</td>\n",
              "      <td>0.851577</td>\n",
              "      <td>0.075828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Teacher (Master)</td>\n",
              "      <td>0.996630</td>\n",
              "      <td>0.786403</td>\n",
              "      <td>0.694805</td>\n",
              "      <td>0.905820</td>\n",
              "      <td>0.843600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Model   ROC AUC  F1-Score    Recall  Precision  Latency (s)\n",
              "2      XGBoost (Tuned)  0.999745  0.908788  0.885552   0.933276     0.384750\n",
              "3        Random Forest  0.993781  0.859232  0.762987   0.983264     0.559111\n",
              "1  Student (Distilled)  0.997468  0.794805  0.745130   0.851577     0.075828\n",
              "0     Teacher (Master)  0.996630  0.786403  0.694805   0.905820     0.843600"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------\n",
            "Student model is 5.07x faster than xgboost\n",
            "Student model: 0.075828s XGBoost model: 0.384750s\n"
          ]
        }
      ],
      "source": [
        "results_paysim_final = []\n",
        "\n",
        "results_paysim_final.append(full_benchmark(\n",
        "    teacher, X_test, y_test, \"Teacher (Master)\", is_torch=True, threshold=best_t_teacher\n",
        "))\n",
        "\n",
        "results_paysim_final.append(full_benchmark(\n",
        "    student, X_test, y_test, \"Student (Distilled)\", is_torch=True, threshold=best_t_student\n",
        "))\n",
        "\n",
        "results_paysim_final.append(full_benchmark(\n",
        "    xgb_model, X_test, y_test, \"XGBoost (Tuned)\", is_torch=False, threshold=best_t_xgb\n",
        "))\n",
        "\n",
        "results_paysim_final.append(full_benchmark(\n",
        "    rf_model, X_test, y_test, \"Random Forest\", is_torch=False, threshold=0.5\n",
        "))\n",
        "\n",
        "df_paysim_res = pd.DataFrame(results_paysim_final)\n",
        "\n",
        "print(\"\\n Final comparison: PaySim Dataset (10 Features)\")\n",
        "display(df_paysim_res.sort_values(by=\"F1-Score\", ascending=False))\n",
        "\n",
        "xgb_latency = df_paysim_res.loc[df_paysim_res['Model'] == 'XGBoost (Tuned)', 'Latency (s)'].values[0]\n",
        "student_latency = df_paysim_res.loc[df_paysim_res['Model'] == 'Student (Distilled)', 'Latency (s)'].values[0]\n",
        "\n",
        "print(\"-\" * 50)\n",
        "print(f\"Student model is {xgb_latency / student_latency:.2f}x faster than xgboost\")\n",
        "print(f\"Student model: {student_latency:.6f}s XGBoost model: {xgb_latency:.6f}s\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
